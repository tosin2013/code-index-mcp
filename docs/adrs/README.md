# Architectural Decision Records (ADRs)

This directory contains Architectural Decision Records (ADRs) documenting key design decisions for the Code Index MCP project.

## What are ADRs?

ADRs capture important architectural decisions along with their context and consequences. Each ADR describes:
- **Context**: The situation and forces at play
- **Decision**: The architecture/design decision made
- **Consequences**: The resulting context after applying the decision

## Quick Reference

| ADR | Title | Status | Key Decision |
|-----|-------|--------|--------------|
| [0001](0001-mcp-stdio-protocol-cloud-deployment-constraints.md) | MCP Transport Protocols | ‚úÖ Implemented | Support both stdio (local) and HTTP/SSE (cloud) transports |
| [0002](0002-cloud-run-http-deployment-with-auto-cleanup.md) | Cloud Run HTTP Deployment | ‚úÖ Implemented | Deploy to Cloud Run with automatic resource cleanup |
| [0003](0003-google-cloud-code-ingestion-with-alloydb.md) | Google Cloud Code Ingestion | üöß Future | Use AlloyDB + Vertex AI for semantic search (GCP) |
| [0004](0004-aws-code-ingestion-with-aurora-and-bedrock.md) | AWS Code Ingestion | üöß Future | Use Aurora PostgreSQL + Bedrock (AWS) |
| [0005](0005-openshift-code-ingestion-with-milvus.md) | OpenShift Code Ingestion | üöß Future | Use Milvus + vLLM + ODF (OpenShift) |
| [0006](0006-aws-http-deployment-with-auto-cleanup.md) | AWS HTTP Deployment | üöß Future | Deploy to Lambda/ECS with EventBridge cleanup |
| [0007](0007-openshift-http-deployment-with-auto-cleanup.md) | OpenShift HTTP Deployment | üöß Future | Deploy to OpenShift with CronJob cleanup |
| [0008](0008-git-sync-ingestion-strategy.md) | Git-Sync Ingestion Strategy | ‚úÖ Implemented | Use git-sync for efficient code ingestion with webhooks |
| [0009](0009-ansible-deployment-automation.md) | Ansible Deployment Automation | ‚úÖ Implemented | Use Ansible for deployment and operational tasks |
| [0010](0010-mcp-server-testing-with-ansible.md) | MCP Server Testing with Ansible | ‚úÖ Accepted | Use tosin2013.mcp_audit for automated MCP testing |

## Decision Timeline

```
2025-10-24 - 2025-11-02
‚îú‚îÄ‚îÄ Transport & Core
‚îÇ   ‚îî‚îÄ‚îÄ ADR 0001: MCP Transport Protocols ‚úÖ
‚îÇ
‚îú‚îÄ‚îÄ HTTP Deployments
‚îÇ   ‚îú‚îÄ‚îÄ ADR 0002: Google Cloud Run HTTP Deployment ‚úÖ
‚îÇ   ‚îú‚îÄ‚îÄ ADR 0006: AWS HTTP Deployment (Lambda/ECS) üöß
‚îÇ   ‚îî‚îÄ‚îÄ ADR 0007: OpenShift HTTP Deployment üöß
‚îÇ
‚îú‚îÄ‚îÄ Code Ingestion (Semantic Search)
‚îÇ   ‚îú‚îÄ‚îÄ ADR 0003: Google Cloud Ingestion (AlloyDB) üöß
‚îÇ   ‚îú‚îÄ‚îÄ ADR 0004: AWS Ingestion (Aurora + Bedrock) üöß
‚îÇ   ‚îú‚îÄ‚îÄ ADR 0005: OpenShift Ingestion (Milvus + vLLM) üöß
‚îÇ   ‚îî‚îÄ‚îÄ ADR 0008: Git-Sync Ingestion Strategy ‚úÖ
‚îÇ
‚îî‚îÄ‚îÄ DevOps & Automation
    ‚îú‚îÄ‚îÄ ADR 0009: Ansible Deployment Automation ‚úÖ
    ‚îî‚îÄ‚îÄ ADR 0010: MCP Server Testing with Ansible ‚úÖ
```

## ADR Summaries

### ADR 0001: MCP Transport Protocols and Cloud Deployment Architecture

**Status**: ‚úÖ Implemented

**Problem**: How to support both local development and cloud deployment?

**Decision**: Implement dual transport support in FastMCP:
- **stdio transport** (default) - For local execution, spawned as subprocess
- **HTTP/SSE transport** - For cloud deployment, standard HTTP endpoint

**Key Code**:
```python
def create_mcp_server():
    transport = os.getenv("MCP_TRANSPORT", "stdio")

    if transport == "http":
        return FastMCP("CodeIndexer", transport="sse", port=8080)
    else:
        return FastMCP("CodeIndexer")  # stdio default
```

**Impact**:
- ‚úÖ Zero deployment complexity for individual developers
- ‚úÖ Full cloud deployment capability for teams
- ‚úÖ Same codebase for both modes
- ‚ùå HTTP mode requires cloud infrastructure setup

**Related**: Supersedes previous SSH-based deployment approach

---

### ADR 0002: Cloud Run HTTP Deployment with Automatic Resource Cleanup

**Status**: ‚úÖ Implemented

**Problem**: How to deploy to Google Cloud Run securely with multi-project support and prevent cost accumulation?

**Decision**: Deploy using HTTP/SSE transport with multi-layer cleanup strategy:

1. **Architecture**:
   - Cloud Run with auto-scale to zero (no idle costs)
   - Cloud Storage for user code (multi-tenant namespaces)
   - API key authentication
   - Secret Manager for credentials (no keys in git)

2. **Multi-Project Isolation**:
   ```
   gs://project-code-storage/
   ‚îú‚îÄ‚îÄ users/
   ‚îÇ   ‚îú‚îÄ‚îÄ user_abc123/project_1/
   ‚îÇ   ‚îú‚îÄ‚îÄ user_abc123/project_2/
   ‚îÇ   ‚îî‚îÄ‚îÄ user_xyz789/project_1/
   ```

3. **Automatic Cleanup**:
   - Cloud Scheduler jobs (daily cleanup of 30+ day idle projects)
   - Storage lifecycle rules (archive after 30 days, delete after 90)
   - Budget alerts to prevent cost overruns

**Key Security**:
- Never commit credentials (comprehensive .gitignore)
- Use Workload Identity (no service account keys)
- API keys stored in Secret Manager
- HTTPS only

**Impact**:
- ‚úÖ True serverless (scales to zero)
- ‚úÖ Multi-user with isolation
- ‚úÖ Automatic cost control
- ‚úÖ ~$3/month for typical team usage
- ‚ùå Cold start latency (5-10s after idle)

**Deployment**:
```bash
cd deployment/gcp
./deploy.sh
```

---

### ADR 0003: Google Cloud Code Ingestion with AlloyDB

**Status**: üöß Future Enhancement

**Problem**: How to enable semantic code search in Google Cloud deployments?

**Decision**: Use AlloyDB PostgreSQL with pgvector for vector similarity search and Vertex AI for embeddings.

**Architecture**:
```
Cloud Run (MCP Server)
    ‚Üì
AlloyDB (pgvector + Vertex AI integration)
    ‚Üì
Vertex AI (textembedding-gecko@003)
    ‚Üì
Cloud Storage (Code + Indexes)
```

**Key Features**:
- AlloyDB's native Vertex AI integration (SQL function)
- HNSW index for fast vector similarity search
- 1536-dimensional embeddings
- Full-text search combined with semantic search

**Schema Example**:
```sql
CREATE TABLE code_chunks (
    chunk_id UUID PRIMARY KEY,
    content TEXT NOT NULL,
    embedding vector(1536),  -- Vertex AI dimensions
    metadata JSONB,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX code_chunks_embedding_idx ON code_chunks
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);
```

**Cost**: ~$220/month for production workload

**Impact**:
- ‚úÖ Native GCP integration
- ‚úÖ Managed embedding generation
- ‚úÖ High performance with HNSW
- ‚ùå Higher cost than alternatives
- ‚ùå Vendor lock-in to Google Cloud

**Related**: Complements ADR 0002 (Cloud Run deployment)

---

### ADR 0004: AWS Code Ingestion with Aurora PostgreSQL and Amazon Bedrock

**Status**: üöß Future Enhancement

**Problem**: How to enable semantic code search in AWS deployments?

**Decision**: Use Aurora PostgreSQL Serverless v2 with pgvector and Amazon Bedrock for embeddings.

**Architecture**:
```
Lambda/ECS (MCP Server)
    ‚Üì
Aurora PostgreSQL Serverless v2 (pgvector)
    ‚Üì
Amazon Bedrock (Titan Embeddings)
    ‚Üì
S3 (Code + Indexes)
```

**Key Differences from Google Cloud**:
- Aurora Serverless v2 (scales to zero like Cloud Run)
- Amazon Bedrock Titan Embeddings ($0.10 per 1M tokens)
- Lambda or ECS for compute
- 3x cheaper than Google Cloud (~$65/month vs ~$220/month)

**Trade-offs**:
- ‚úÖ **Cost-effective** (lowest cost option)
- ‚úÖ Serverless database (scales to zero)
- ‚úÖ Pay-per-use embeddings
- ‚ùå Less tight integration (separate API calls for embeddings)
- ‚ùå No native SQL embedding function

**Deployment**:
```bash
cd deployment/aws
./deploy.sh
```

**Related**: Parallel implementation to ADR 0003 (Google Cloud)

---

### ADR 0005: OpenShift Code Ingestion with Milvus, vLLM, and ODF

**Status**: üöß Future Enhancement

**Problem**: How to enable semantic code search in OpenShift (Kubernetes) deployments, especially for on-premise and air-gapped environments?

**Decision**: Use Milvus vector database, vLLM for embeddings, and OpenShift Data Foundation for S3-compatible storage.

**Architecture**:
```
OpenShift Pod (MCP Server)
    ‚Üì
Milvus (Vector database with HNSW index)
    ‚Üì
vLLM (E5-Mistral-7B embeddings with GPU)
    ‚Üì
OpenShift Data Foundation (S3-compatible via Ceph/NooBaa)
```

**Key Components**:

1. **Milvus** - Open-source vector database
   - HNSW/IVF_FLAT indexes for fast similarity search
   - Horizontal scaling with query nodes
   - S3 backend for storage

2. **vLLM** - High-performance LLM inference
   - Production-grade (vs. Ollama for dev)
   - GPU acceleration (NVIDIA T4/A10/A100)
   - OpenAI-compatible API
   - Models: E5-Mistral-7B, BGE-Large, E5-Base

3. **OpenShift Data Foundation (ODF)**
   - S3-compatible API via Ceph/NooBaa
   - Multi-cloud object storage
   - Block storage for PostgreSQL/Milvus
   - Built-in data protection

**Storage Structure**:
```
ODF S3 (via NooBaa):
‚îî‚îÄ‚îÄ code-storage-bucket/
    ‚îú‚îÄ‚îÄ users/
    ‚îÇ   ‚îú‚îÄ‚îÄ user_abc123/project_1/
    ‚îÇ   ‚îî‚îÄ‚îÄ user_xyz789/project_1/

ODF Block (PVCs):
‚îú‚îÄ‚îÄ postgresql-data (16Gi)
‚îî‚îÄ‚îÄ milvus-data (32Gi)
```

**Deployment**:
```bash
cd deployment/openshift
helm install code-index-mcp ./helm-chart
```

**Hardware Requirements**:
- CPU: 4+ cores per node
- Memory: 16+ GB per node
- GPU: NVIDIA T4/A10/A100 (for vLLM)
- Storage: 50+ GB ODF

**Impact**:
- ‚úÖ **Open-source stack** (no vendor lock-in)
- ‚úÖ **On-premise ready** (no external dependencies)
- ‚úÖ **Air-gap capable** (all components self-hosted)
- ‚úÖ **Production-grade inference** (vLLM)
- ‚úÖ **Cost-effective for large scale** (one-time hardware)
- ‚ùå Requires GPU infrastructure
- ‚ùå More complex setup than cloud services
- ‚ùå Manual scaling and maintenance

**Related**: Alternative to ADR 0003 (Google Cloud) and ADR 0004 (AWS) for on-premise

---

### ADR 0006: AWS HTTP Deployment with Automatic Resource Cleanup

**Status**: üöß Future Enhancement

**Problem**: How to deploy code-index-mcp to AWS with HTTP/SSE transport, multi-user support, and automatic resource cleanup?

**Decision**: Deploy using Lambda (serverless) or ECS Fargate (containerized) with API Gateway, EventBridge cleanup, and S3 storage.

**Architecture Options**:

**Option A: Lambda + API Gateway** (Recommended for light usage)
```
API Gateway ‚Üí Lambda ‚Üí S3 Storage
- True serverless (pay per request)
- 15-minute timeout limit
- Cold start latency (~1-3s)
```

**Option B: ECS Fargate + ALB** (Recommended for heavy usage)
```
ALB ‚Üí ECS Fargate ‚Üí S3 Storage
- Longer running tasks (no timeout)
- Minimum $10/month (cannot scale to zero)
- Better for continuous services
```

**Key Features**:

1. **Multi-Project Isolation**:
   ```
   s3://account-code-storage/
   ‚îî‚îÄ‚îÄ users/
       ‚îú‚îÄ‚îÄ user_abc123/project_1/
       ‚îî‚îÄ‚îÄ user_xyz789/project_1/
   ```

2. **Automatic Cleanup**:
   - EventBridge rules (daily cleanup of 30+ day idle projects)
   - S3 lifecycle policies (archive after 30 days, delete after 90)
   - Budget alerts to prevent cost overruns

3. **Security**:
   - API Gateway authentication
   - AWS Secrets Manager for API keys
   - IAM execution roles (no access keys)

**Cost Comparison**:
- Lambda option: ~$2.50/month (12x cheaper than Google Cloud!)
- ECS option: ~$27/month (8x cheaper than Google Cloud!)
- Google Cloud Run: ~$220/month

**Deployment**:
```bash
cd deployment/aws
./deploy-lambda.sh  # or ./deploy-ecs.sh
```

**Impact**:
- ‚úÖ **Lowest cost option** ($2.50/month with Lambda)
- ‚úÖ True serverless with Lambda (scales to zero)
- ‚úÖ Flexible (choose Lambda or ECS based on needs)
- ‚ùå Lambda 15-minute timeout (use ECS for longer operations)
- ‚ùå More services to manage than Cloud Run

**Related**: Parallel to ADR 0002 (Google Cloud Run), complements ADR 0004 (AWS Code Ingestion)

---

### ADR 0007: OpenShift HTTP Deployment with Automatic Resource Cleanup

**Status**: üöß Future Enhancement

**Problem**: How to deploy code-index-mcp to OpenShift/Kubernetes with HTTP/SSE transport, multi-user support, and automatic resource cleanup?

**Decision**: Deploy using Kubernetes Deployment with OpenShift Route, CronJob cleanup, and ODF/PVC storage.

**Architecture**:
```
OpenShift Route (HTTPS edge)
    ‚Üì
Service (ClusterIP)
    ‚Üì
Pods (2 replicas, HPA)
    ‚Üì
ODF S3 / PVCs (user storage)
```

**Key Features**:

1. **Multi-Project Isolation**:
   - Option A: ODF S3 (ObjectBucketClaim per user)
   - Option B: PVCs (PersistentVolumeClaim per user)

2. **Automatic Cleanup**:
   - CronJob (daily cleanup of 30+ day idle projects)
   - Storage lifecycle policies via ODF
   - Resource quotas to prevent overuse

3. **Security**:
   - NetworkPolicy for ingress/egress control
   - SecurityContextConstraints (OpenShift-specific)
   - Sealed Secrets or External Secrets Operator
   - RBAC for service accounts

4. **Auto-Scaling**:
   - Horizontal Pod Autoscaler (min: 1, max: 10)
   - Note: Cannot scale to zero with standard HPA
   - Consider KEDA or Knative for true zero scaling

**Storage Options**:

**ODF S3** (Recommended):
```yaml
apiVersion: objectbucket.io/v1alpha1
kind: ObjectBucketClaim
metadata:
  name: code-storage-user-abc123
spec:
  generateBucketName: code-index-user-abc123
  storageClassName: openshift-storage.noobaa.io
```

**PVCs** (Alternative):
```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: code-storage-user-abc123
spec:
  accessModes: [ReadWriteMany]
  resources:
    requests:
      storage: 50Gi
  storageClassName: ocs-storagecluster-cephfs
```

**Cost Comparison**:
- Managed OpenShift (ROSA/ARO): ~$600/month
- Self-hosted OpenShift: ~$4,887/month (hardware + license)
- Google Cloud Run: ~$220/month
- AWS Lambda: ~$2.50/month

**Note**: OpenShift is cost-effective only for:
- Large-scale deployments (100+ services)
- On-premise requirements
- Air-gapped environments
- Organizations with existing OpenShift infrastructure

**Deployment**:
```bash
cd deployment/openshift
./deploy.sh
# or
helm install code-index-mcp ./helm-chart
```

**Impact**:
- ‚úÖ **On-premise deployment** (no cloud dependency)
- ‚úÖ **Air-gap capable** (all components self-hosted)
- ‚úÖ **Enterprise security** (RBAC, NetworkPolicy, SCC)
- ‚úÖ **Kubernetes-native** (portable to other K8s)
- ‚ùå Cannot scale to zero (minimum 1 replica)
- ‚ùå Highest cost option (unless at large scale)
- ‚ùå More complex setup than cloud services

**Related**: Parallel to ADR 0002 (Google Cloud Run), complements ADR 0005 (OpenShift Code Ingestion)

---

## Decision Principles

All architectural decisions in this project follow these principles:

1. **Local-First**: Prioritize local development experience
2. **Optional Cloud**: Cloud features are enhancements, not requirements
3. **Platform-Native**: Use cloud-native services for each platform
4. **Cost-Conscious**: Implement auto-cleanup and scale-to-zero
5. **Open Standards**: Prefer open protocols and formats
6. **Security by Default**: Never commit credentials, use managed secrets

## Creating New ADRs

When making a significant architectural decision:

1. **Create a new ADR file**: `docs/adrs/NNNN-title-with-dashes.md`
2. **Use the template**:
   ```markdown
   # ADR NNNN: Title

   **Status**: Proposed | Accepted | Implemented | Deprecated | Superseded
   **Date**: YYYY-MM-DD
   **Decision Maker**: Team/Role

   ## Context
   What is the issue that we're seeing that is motivating this decision?

   ## Decision
   What is the change that we're proposing and/or doing?

   ## Consequences
   What becomes easier or more difficult to do because of this change?

   ## Related ADRs
   Links to related decisions
   ```
3. **Update this README**: Add entry to the table and timeline
4. **Update CLAUDE.md**: If the decision affects development workflows

## Implementation Roadmap

For a comprehensive implementation plan with detailed steps, timelines, and dependencies, see:

**üìã [Implementation Plan](../IMPLEMENTATION_PLAN.md)**

This document provides:
- Complete implementation sequences for all platforms
- Week-by-week task breakdowns
- Success criteria and testing checklists
- Risk management strategies
- Platform selection decision tree

**Quick Links**:
- [Phase 2: HTTP Deployments](../IMPLEMENTATION_PLAN.md#phase-2-http-deployments) - Basic cloud deployment
- [Phase 3: Semantic Search](../IMPLEMENTATION_PLAN.md#phase-3-semantic-search) - Vector embeddings
- [Platform Selection Guide](../IMPLEMENTATION_PLAN.md#platform-selection-guide) - Choose your platform

## References

- [Implementation Plan](../IMPLEMENTATION_PLAN.md) - Detailed roadmap and task breakdown
- [Cloud Deployment Guide](../DEPLOYMENT.md) - Platform-specific deployment instructions
- [ADR Documentation](https://adr.github.io/) - ADR methodology
- [MCP Specification](https://spec.modelcontextprotocol.io/) - Model Context Protocol
- [FastMCP Documentation](https://github.com/jlowin/fastmcp) - Python MCP framework
